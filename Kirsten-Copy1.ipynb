{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Final-Project-Check-in\" data-toc-modified-id=\"Final-Project-Check-in-1\">Final Project Check-in</a></span></li><li><span><a href=\"#Group-Name\" data-toc-modified-id=\"Group-Name-2\">Group Name</a></span></li><li><span><a href=\"#Student-Names\" data-toc-modified-id=\"Student-Names-3\">Student Names</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\">Load Data</a></span></li><li><span><a href=\"#Fit-scikit-learn-model\" data-toc-modified-id=\"Fit-scikit-learn-model-5\">Fit scikit-learn model</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-6\">Evaluation Metric</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Check-in\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kakkle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Names\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Annette (Zijun) Lin\n",
    "2. Ming-Chuan Tsai\n",
    "3. Kathy Yi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"forestfires.csv\")\n",
    "\n",
    "df['month'] = df['month'].map({'mar':3, 'oct':10, 'aug':8, 'sep':9, 'apr':4, 'jun':6, 'jul':7, 'feb':2, 'jan':1,\n",
    "       'dec':12, 'may':5, 'nov':11})\n",
    "df['day'] = df['day'].map({'fri': 5, 'tue': 2, 'sat': 6, 'sun': 7, 'mon': 1, 'wed': 3, 'thu':4})\n",
    "df.loc[df.area >= 100, 'label'] = \"large\"\n",
    "df.loc[(df.area >= 30) & (df.area < 100), 'label'] = \"medium\"\n",
    "df.loc[(df.area < 30), 'label'] = \"small\"\n",
    "\n",
    "# df = pd.get_dummies(df,prefix=['fire'], drop_first=True)\n",
    "\n",
    "y = df.label.values\n",
    "X = df.drop([\"area\", \"label\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipelines():\n",
    "    \"\"\"Create a pipeline for each of the following algorithms:\n",
    "    1. Logistic Regression\n",
    "    2. k-nearest neighbors (KNN) \n",
    "    3. Naive Bayes (Guassian)\n",
    "    4. Support Vector Machines (SVM)\n",
    "    5. Random Forestâ„¢ \n",
    "    \n",
    "    If appropriate, apply StandardScaler before the algorithm.   \n",
    "    Use default hyperparameters.\n",
    "    If an algorithm takes random_state then random_state=42 \n",
    "    \n",
    "    Return a list of all the pipelines.\n",
    "    \"\"\" \n",
    "#     ('scl', StandardScaler()),          # Transformer: Standardize\n",
    "#                     ('pca', PCA(n_components=2)),       # Transformer: Dimension Reduction\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     solver='lbfgs', # Estimator: ML algorithm\n",
    "#                                                multi_class='multinomial',\n",
    "#                                                random_state=42\n",
    "    pipe_lr = Pipeline([('scl', StandardScaler()),          # Transformer: Standardize\n",
    "                    ('clf', LogisticRegression())]) \n",
    "    pipe_knn = Pipeline([('scl', StandardScaler()),\n",
    "                        ('knn', KNeighborsClassifier())])\n",
    "    pipe_nb = Pipeline([('scl', StandardScaler()),\n",
    "                       ('gaussiannb', GaussianNB())])\n",
    "    \n",
    "    pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "                        ('svm', SVC(random_state=42))])\n",
    "    \n",
    "    pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "                        ('classifier', RandomForestClassifier(min_samples_split=5, random_state=42))])\n",
    "    \n",
    "    pipelines = [pipe_lr, pipe_knn, pipe_nb, pipe_svm, pipe_rf]\n",
    "    \n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipelines = make_pipelines()\n",
    "# Train all the models\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def sort_models(pipelines, X_data, y_data, metric=f1_score, average='weighted'):\n",
    "    scoresDict = dict()\n",
    "    nameList = ['LogisticRegression','KNeighborsClassifier', 'GaussianNB',  'SVC', 'RandomForestClassifier']\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for model in range(len(pipelines)):\n",
    "        pipe = pipelines[model]\n",
    "        print(pipe.steps[-1][1].__class__.__name__.split('.')[-1])\n",
    "        pipelines[model].fit(X_data, y_data)\n",
    "        y = pipelines[model].predict(X_data)\n",
    "        score = f1_score(y_true=y_data, y_pred=y, average=average)\n",
    "        scoresDict[nameList[model]]=score\n",
    "        print(confusion_matrix(y_data, y))\n",
    "    scores_sorted = dict(sorted(scoresDict.items(), key=lambda x: x[1], reverse=True))\n",
    "    print(scores_sorted)\n",
    "# sorted_x = sorted(x.items(), key=lambda kv: kv[1])\n",
    "    return scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "[[  0   0   9]\n",
      " [  0   0  23]\n",
      " [  0   0 381]]\n",
      "KNeighborsClassifier\n",
      "[[  0   0   9]\n",
      " [  0   0  23]\n",
      " [  0   0 381]]\n",
      "GaussianNB\n",
      "[[  8   1   0]\n",
      " [  8  15   0]\n",
      " [139 221  21]]\n",
      "SVC\n",
      "[[  0   0   9]\n",
      " [  0   0  23]\n",
      " [  0   0 381]]\n",
      "RandomForestClassifier\n",
      "[[  4   0   5]\n",
      " [  0   7  16]\n",
      " [  0   0 381]]\n",
      "{'RandomForestClassifier': 0.9371753125113734, 'LogisticRegression': 0.8853385866151096, 'KNeighborsClassifier': 0.8853385866151096, 'SVC': 0.8853385866151096, 'GaussianNB': 0.10493429802321477}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_sorted_train = sort_models(pipelines, X_train, y_train, metric=f1_score, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "[[ 0  0  2]\n",
      " [ 0  0  9]\n",
      " [ 0  0 93]]\n",
      "KNeighborsClassifier\n",
      "[[ 0  0  2]\n",
      " [ 0  0  9]\n",
      " [ 0  0 93]]\n",
      "GaussianNB\n",
      "[[ 2  0  0]\n",
      " [ 0  9  0]\n",
      " [ 4 86  3]]\n",
      "SVC\n",
      "[[ 0  0  2]\n",
      " [ 0  0  9]\n",
      " [ 0  0 93]]\n",
      "RandomForestClassifier\n",
      "[[ 0  0  2]\n",
      " [ 0  2  7]\n",
      " [ 0  0 93]]\n",
      "{'RandomForestClassifier': 0.8844271113501883, 'LogisticRegression': 0.8442991019133151, 'KNeighborsClassifier': 0.8442991019133151, 'SVC': 0.8442991019133151, 'GaussianNB': 0.08048261834319526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathleenyi/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_sorted_test = sort_models(pipelines, X_test, y_test, metric=f1_score, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scikit-learn model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = np.array([int(i) for i in y_train])\n",
    "y_test2 = np.array([int(i) for i in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirsten/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/kirsten/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression() # TODO: Replace with your choice of hyperparameters \n",
    "clf.fit(X=X_train, y=y_train) # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48184019370460046"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E', 'E', 'D', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'D', 'D', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'C',\n",
       "       'E', 'E', 'E', 'E', 'D', 'D', 'E', 'D', 'E', 'E', 'E', 'D', 'D',\n",
       "       'D', 'E', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'D',\n",
       "       'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'D', 'D',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'C', 'E', 'E', 'E', 'D',\n",
       "       'E', 'E', 'E', 'E', 'D', 'E', 'E', 'D', 'E', 'D', 'E', 'D', 'D',\n",
       "       'E', 'E', 'E', 'D', 'D', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'D', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E',\n",
       "       'D', 'E', 'E', 'D', 'E', 'D', 'E', 'E', 'E', 'E', 'D', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'D', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'D', 'D', 'E', 'E', 'D', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'D', 'E', 'D', 'E', 'E', 'D', 'D', 'E',\n",
       "       'E', 'E', 'E', 'D', 'E', 'E', 'D', 'C', 'E', 'D', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'D', 'E', 'E', 'E', 'D', 'E', 'D', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'D', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'D', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'D', 'D', 'E', 'E', 'E', 'E', 'D',\n",
       "       'E', 'E', 'E', 'D', 'D', 'E', 'D', 'E', 'D', 'D', 'E', 'E', 'E',\n",
       "       'E', 'D', 'E', 'C', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'D',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E',\n",
       "       'E', 'D', 'D', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'D', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'D', 'D', 'E', 'E', 'E', 'E',\n",
       "       'E', 'E', 'E', 'E', 'E', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'D',\n",
       "       'E', 'D', 'D', 'D', 'E', 'E', 'C', 'E', 'E', 'E', 'D', 'E', 'D',\n",
       "       'D', 'E', 'E', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'D', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>fire_B</th>\n",
       "      <th>fire_C</th>\n",
       "      <th>fire_D</th>\n",
       "      <th>fire_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.669246</td>\n",
       "      <td>4.299807</td>\n",
       "      <td>7.475822</td>\n",
       "      <td>4.259188</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.137331</td>\n",
       "      <td>0.338491</td>\n",
       "      <td>0.477756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.313778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>2.275990</td>\n",
       "      <td>2.072929</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.156717</td>\n",
       "      <td>0.344530</td>\n",
       "      <td>0.473655</td>\n",
       "      <td>0.499989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y       month         day        FFMC         DMC  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     4.669246    4.299807    7.475822    4.259188   90.644681  110.872340   \n",
       "std      2.313778    1.229900    2.275990    2.072929    5.520111   64.046482   \n",
       "min      1.000000    2.000000    1.000000    1.000000   18.700000    1.100000   \n",
       "25%      3.000000    4.000000    7.000000    2.000000   90.200000   68.600000   \n",
       "50%      4.000000    4.000000    8.000000    5.000000   91.600000  108.300000   \n",
       "75%      7.000000    5.000000    9.000000    6.000000   92.900000  142.400000   \n",
       "max      9.000000    9.000000   12.000000    7.000000   96.200000  291.300000   \n",
       "\n",
       "               DC         ISI        temp          RH        wind        rain  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean   547.940039    9.021663   18.889168   44.288201    4.017602    0.021663   \n",
       "std    248.066192    4.559477    5.806625   16.317469    1.791653    0.295959   \n",
       "min      7.900000    0.000000    2.200000   15.000000    0.400000    0.000000   \n",
       "25%    437.700000    6.500000   15.500000   33.000000    2.700000    0.000000   \n",
       "50%    664.200000    8.400000   19.300000   42.000000    4.000000    0.000000   \n",
       "75%    713.900000   10.800000   22.800000   53.000000    4.900000    0.000000   \n",
       "max    860.600000   56.100000   33.300000  100.000000    9.400000    6.400000   \n",
       "\n",
       "              area      fire_B      fire_C      fire_D      fire_E  \n",
       "count   517.000000  517.000000  517.000000  517.000000  517.000000  \n",
       "mean     12.847292    0.025145    0.137331    0.338491    0.477756  \n",
       "std      63.655818    0.156717    0.344530    0.473655    0.499989  \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%       0.520000    0.000000    0.000000    0.000000    0.000000  \n",
       "75%       6.570000    0.000000    0.000000    1.000000    1.000000  \n",
       "max    1090.840000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gt10 = X[np.where(y > 10)[0]]\n",
    "y_gt10 = y[np.where(y > 10)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 3., 9., ..., 0., 1., 0.],\n",
       "       [4., 4., 9., ..., 0., 1., 0.],\n",
       "       [2., 5., 8., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [2., 2., 8., ..., 0., 1., 0.],\n",
       "       [2., 5., 7., ..., 0., 0., 1.],\n",
       "       [2., 4., 8., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170143487948007"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(self, X_test, y_test):\n",
    "    pre_y = [self.root.predict(i) for i in X_test]\n",
    "    ybar = np.mean(pre_y)        \n",
    "    ssreg = np.sum((pre_y-ybar)**2)   \n",
    "    sstot = np.sum((y_test - ybar)**2)   \n",
    "    return ssreg / sstot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 16.950140694735225,\n",
       " 32.92787953271066,\n",
       " 0,\n",
       " 10.366681143327371,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11.329673583380671,\n",
       " 10.209277246235853,\n",
       " 19.389787759818816,\n",
       " 0,\n",
       " 11.599660737406023,\n",
       " 0,\n",
       " 0,\n",
       " 12.948052182169745,\n",
       " 21.756773170526806,\n",
       " 10.262760114835213,\n",
       " 0,\n",
       " 16.188708921245613,\n",
       " 20.547686374812578,\n",
       " 16.362888179109536,\n",
       " 0,\n",
       " 26.701901925479874,\n",
       " 11.218158147942436,\n",
       " 31.17997570310765,\n",
       " 13.762541483906995,\n",
       " 0,\n",
       " 0,\n",
       " 17.214188498902153,\n",
       " 0,\n",
       " 13.810824504650279,\n",
       " 0,\n",
       " 21.94963708569373,\n",
       " 0,\n",
       " 14.467457035540548,\n",
       " 16.25209493511882,\n",
       " 0,\n",
       " 28.947873013459386,\n",
       " 0,\n",
       " 0,\n",
       " 17.508399030992088,\n",
       " 21.640959050118468,\n",
       " 25.2961409344517,\n",
       " 0,\n",
       " 11.53648131101491,\n",
       " 0,\n",
       " 11.715167213435837,\n",
       " 0,\n",
       " 19.452696543245736,\n",
       " 17.596622272002435,\n",
       " 0,\n",
       " 14.819776918097824,\n",
       " 0,\n",
       " 0,\n",
       " 15.729582908897358,\n",
       " 12.210598135532292,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 20.459794942499755,\n",
       " 0,\n",
       " 17.15699233303964,\n",
       " 14.043250145171692,\n",
       " 0,\n",
       " 28.780728347593282,\n",
       " 18.288116810650116,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12.074971768750979,\n",
       " 0,\n",
       " 13.843183855108446,\n",
       " 17.74069338181735,\n",
       " 13.106210597441892,\n",
       " 10.379577245911983,\n",
       " 0,\n",
       " 11.099532930121077,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 14.814332926032375,\n",
       " 0,\n",
       " 20.457588324530256,\n",
       " 0,\n",
       " 12.20390496580377,\n",
       " 0,\n",
       " 0,\n",
       " 10.749866876889056,\n",
       " 0,\n",
       " 17.98883105579469,\n",
       " 18.867621127167446,\n",
       " 18.04649323506294,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 14.987672952369927]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_trans = []\n",
    "for i in y_pre:\n",
    "    if i > 10:\n",
    "        y_pre_trans.append(i)\n",
    "    else:\n",
    "        y_pre_trans.append(0)\n",
    "y_pre_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025606026443458774"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.11, copy_X=True, eps=2.220446049250313e-16,\n",
       "          fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
       "          positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = linear_model.LassoLars(alpha=0.11) # TODO: Replace with your choice of algorithm and hyperparameters \n",
    "lm.fit(X_train, y_train) # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002500798595874043"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.8134 medae on training set\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "medae_value = metrics.median_absolute_error(y_test, lm.predict(X_test))\n",
    "print(f\"{medae_value:.4f} medae on training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
